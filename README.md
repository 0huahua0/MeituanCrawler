#MeituanCrawler

爬取美团上面 武汉本地药店的数据,保存到本地，并做适当的分析与图表展示



### 获取代理ip策略（IP这段借鉴fancoo的代码，GitHub地址https://github.com/fancoo/BaiduCrawler）

* 1. 抓取页面上全部[ip:port]对，并检测可用性（有的代理ip是连不通的）。
* 2. 使用"多轮检测"策略，即每个ip要经历N轮，间隔为duration连接测试，每轮都会丢弃连接时间超过timeout的ip。N轮下来，存活的ip都是每次都在timeout范围以内连通的，从而避免了"辉煌的15分钟"效应。


有3个策略：
   * 1. 每当出现download_error，更换一个IP
   * 2. 每爬取200条文本，更换一个IP
   * 3. 每爬取20,000次，更新一次IP资源池
  
上述参数均可手动调整。
目前ip池的使用都是一次性的，<b>如果需要更多的优质ip</b>，可参考我的另一个项目[Proxy](https://github.com/fancoo/Proxy),它是一个代理ip抓取测试评估存储一体化工具，也许可以帮到你。


### TODO

* 1. 对因网络原因未爬取的词进行二次爬取，直到达到用户指定的爬取率
* 2. 对爬取速度快的优质ip增加权重，从而形成一个具有优先级的ip池
* 3. ip评估改写成多线程





